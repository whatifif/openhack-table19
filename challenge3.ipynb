{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/36967920/numpy-flatten-rgb-image-array\n",
    "https://table19syd.australiaeast.cloudapp.azure.com:8000/user/table19syd/tree/OpenHack/hacker6/gear_images_out/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirDict = { \n",
    "#     'tents_normalised': 0,\n",
    "#     'gloves_normalised': 1,\n",
    "#     'pulleys_normalised': 2,\n",
    "#     'hardshell_jackets_normalised': 3,\n",
    "#     'rope_normalised': 4,\n",
    "#     'crampons_normalised': 5,\n",
    "#     'boots_normalised': 6,\n",
    "#     'insulated_jackets_normalised': 7,\n",
    "#     'harnesses_normalised': 8,\n",
    "#     'carabiners_normalised': 9,\n",
    "#     'helmets_normalised': 10,\n",
    "#     '.ipynb_checkpoints_normalised': None,\n",
    "#     'axes_normalised': 11,\n",
    "#     '.ipynb_checkpoints': None\n",
    "# }\n",
    "# y_data = []\n",
    "# for root, dirs, files in os.walk(\"./gear_images_out/output\"):\n",
    "#     for name in dirs:\n",
    "# #         print(dirDict[name])\n",
    "#         dirInt = dirDict[name]\n",
    "#         if dirInt != None:\n",
    "# #             print(dirInt)\n",
    "#             y_data.append(dirInt)\n",
    "# y_data = np.array(y_data)\n",
    "# print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# x_data = []\n",
    "# y_data=[]\n",
    "# #flatten data\n",
    "\n",
    "# for image in os.listdir(\"./gear_images_out/output\"):\n",
    "#     pixels =  np.array(cv2.imread(path)\n",
    "#     pixels = pixels.flatten()\n",
    "                        \n",
    "# for imagePath in os.walk(\"./gear_images_out/output\"):\n",
    "#         x_data.append(getpixels(imagePath))\n",
    "#         print(x_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #name = \"./gear_images/output/axes_normalized\"\n",
    "# #print(os.path.basename(name))\n",
    "\n",
    "# y_data = []\n",
    "\n",
    "# for root, dirs, files in os.walk(\"./gear_images_out/output\"):\n",
    "#     for name in dirs:\n",
    "#                 temp_data = os.path.join(root, name)\n",
    "# #                 print (temp_data)\n",
    "#                 if temp_data.endswith(\"normalised\"):\n",
    "#                     for image in os.listdir(temp_data):\n",
    "#                         y_data.append(os.path.basename(temp_data))\n",
    "# # print(y_data)\n",
    "\n",
    "# # y_data2 = map(lambda x: dirDict[x], y_data)\n",
    "# # print(np.array(y_data2))\n",
    "\n",
    "# y_data_int = []\n",
    "# for i in y_data:\n",
    "# #     print(dirDict[i])\n",
    "#     y_data_int.append(dirDict[i])\n",
    "# # print(y_data_int)\n",
    "# y_data = np.array(y_data_int)\n",
    "# print(y_data)\n",
    "# y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image in os.listdir(\"./gear_images_out/output\"):\n",
    "#     pixels =  np.array(cv2.imread(path)\n",
    "#     pixels = pixels.flatten()\n",
    "                        \n",
    "# for imagePath in os.walk(\"./gear_images_out/output\"):\n",
    "#         x_data.append(getpixels(imagePath))\n",
    "#         print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/7762948/how-to-convert-an-rgb-image-to-numpy-array# \n",
    "    \n",
    "# dirDict = { \n",
    "#     'tents_normalised': 0,\n",
    "#     'gloves_normalised': 1,\n",
    "#     'pulleys_normalised': 2,\n",
    "#     'hardshell_jackets_normalised': 3,\n",
    "#     'rope_normalised': 4,\n",
    "#     'crampons_normalised': 5,\n",
    "#     'boots_normalised': 6,\n",
    "#     'insulated_jackets_normalised': 7,\n",
    "#     'harnesses_normalised': 8,\n",
    "#     'carabiners_normalised': 9,\n",
    "#     'helmets_normalised': 10,\n",
    "#     '.ipynb_checkpoints_normalised': None,\n",
    "#     'axes_normalised': 11,\n",
    "#     '.ipynb_checkpoints': None\n",
    "# }\n",
    "# x_data = []\n",
    "\n",
    "# for root, dirs, files in os.walk(\"./gear_images_out/output\"):\n",
    "#     for name in dirs:\n",
    "# #         print(dirDict[name])\n",
    "#         dirInt = dirDict[name]\n",
    "#         if dirInt != None:\n",
    "#             x_dir = os.path.join(root, name)\n",
    "# #             print(dirInt)\n",
    "# #             print(os.listdir(y_data))\n",
    "#             for f in os.listdir(x_dir):\n",
    "# #                 print(f)\n",
    "# #                 print(dirInt)\n",
    "#                 im = cv2.imread(os.path.join(x_dir, f))\n",
    "# #                 print(im.shape)\n",
    "# #\n",
    "#                 im = im.flatten()\n",
    "#                 print(im)\n",
    "                \n",
    "\n",
    "# # print(np.array(x_data).flatten())\n",
    "# x_data = np.array(im)\n",
    "\n",
    "# print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2122, 49152)\n",
      "(2122,)\n",
      "[255 255 255 ... 255 255 255]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/7762948/how-to-convert-an-rgb-image-to-numpy-array# \n",
    "    \n",
    "dirDict = { \n",
    "    'tents_normalised': 0,\n",
    "    'gloves_normalised': 1,\n",
    "    'pulleys_normalised': 2,\n",
    "    'hardshell_jackets_normalised': 3,\n",
    "    'rope_normalised': 4,\n",
    "    'crampons_normalised': 5,\n",
    "    'boots_normalised': 6,\n",
    "    'insulated_jackets_normalised': 7,\n",
    "    'harnesses_normalised': 8,\n",
    "    'carabiners_normalised': 9,\n",
    "    'helmets_normalised': 10,\n",
    "    '.ipynb_checkpoints_normalised': None,\n",
    "    'axes_normalised': 11,\n",
    "    '.ipynb_checkpoints': None\n",
    "}\n",
    "x_data = []\n",
    "y_data = []\n",
    "for root, dirs, files in os.walk(\"./gear_images_out/output\"):\n",
    "    for name in dirs:\n",
    "#         print(dirDict[name])\n",
    "        dirInt = dirDict[name]\n",
    "        if dirInt != None:\n",
    "            x_dir = os.path.join(root, name)\n",
    "#             print(dirInt)\n",
    "#             print(os.listdir(y_data))\n",
    "            for f in os.listdir(x_dir):\n",
    "#                 print(f)\n",
    "#                 print(dirInt)\n",
    "                y_data.append(dirInt)\n",
    "                im = cv2.imread(os.path.join(x_dir, f))\n",
    "#                 print(im.shape)\n",
    "#                 print(im)\n",
    "                im = im.flatten()\n",
    "#                 x_data.append(im.tolist())\n",
    "                x_data.append(im)\n",
    "\n",
    "# print(np.array(x_data).flatten())\n",
    "\n",
    "\n",
    "# x_data = np.array(x_data).flatten()\n",
    "\n",
    "print(np.array(x_data).shape) \n",
    "print(np.array(y_data).shape) \n",
    "print(x_data[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "Labels = np.array(y_data)\n",
    "Features = np.array(x_data)\n",
    "\n",
    "## Randomly sample cases to create independent training and test datanr.seed(9988)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 531)\n",
    "X_train = Features[indx[0],]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],]\n",
    "y_test = np.ravel(Labels[indx[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.15733667, 0.15672293, 0.15789165, ..., 0.16145502, 0.15975578,\n",
       "       0.16097559])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print(scaler.fit(X_train))\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic_mod = linear_model.LogisticRegression() \n",
    "#logistic_mod.fit(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_mod = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "forest_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.006 0.89  0.003 0.006 0.039 0.005 0.002 0.034 0.008 0.    0.007 0.   ]\n",
      " [0.    0.032 0.001 0.792 0.012 0.    0.004 0.155 0.001 0.001 0.002 0.   ]\n",
      " [0.002 0.069 0.054 0.048 0.029 0.008 0.006 0.023 0.011 0.013 0.726 0.011]\n",
      " [0.    0.017 0.007 0.836 0.002 0.    0.001 0.136 0.001 0.    0.    0.   ]\n",
      " [0.003 0.056 0.049 0.176 0.109 0.003 0.01  0.535 0.02  0.008 0.031 0.   ]\n",
      " [0.001 0.047 0.027 0.008 0.034 0.008 0.    0.015 0.03  0.012 0.818 0.   ]\n",
      " [0.005 0.012 0.004 0.    0.028 0.051 0.003 0.    0.006 0.018 0.003 0.87 ]\n",
      " [0.    0.005 0.022 0.492 0.    0.    0.    0.481 0.    0.    0.    0.   ]\n",
      " [0.    0.051 0.011 0.008 0.04  0.024 0.031 0.008 0.732 0.051 0.025 0.019]\n",
      " [0.001 0.005 0.    0.001 0.02  0.008 0.947 0.002 0.009 0.003 0.002 0.002]\n",
      " [0.001 0.006 0.006 0.829 0.003 0.    0.007 0.147 0.    0.    0.001 0.   ]\n",
      " [0.    0.967 0.003 0.003 0.01  0.002 0.    0.007 0.007 0.    0.001 0.   ]\n",
      " [0.    0.004 0.006 0.735 0.    0.    0.001 0.253 0.001 0.    0.    0.   ]\n",
      " [0.    0.001 0.001 0.002 0.    0.001 0.    0.    0.001 0.986 0.    0.008]\n",
      " [0.    0.017 0.005 0.003 0.02  0.053 0.006 0.    0.014 0.294 0.01  0.578]]\n",
      "[1, 3, 10, 3, 7, 10, 11, 3, 8, 6, 3, 1, 3, 9, 11]\n",
      "[ 1  3 10  3  7 10 11  3  8  6  3  1  3  9 11]\n"
     ]
    }
   ],
   "source": [
    "probabilities = forest_mod.predict_proba(X_test)\n",
    "print(probabilities[:15,])\n",
    "\n",
    "def score_model(probs):\n",
    "    scores = []\n",
    "    for x in probs:\n",
    "        scores.append(np.argmax(x))\n",
    "    return scores\n",
    "\n",
    "scores = score_model(probabilities)\n",
    "print(scores[:15])\n",
    "print(y_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        32\n",
      "          1       0.94      0.94      0.94        49\n",
      "          2       1.00      0.60      0.75        10\n",
      "          3       0.82      0.90      0.86       116\n",
      "          4       1.00      0.88      0.94        60\n",
      "          5       0.76      0.96      0.85        27\n",
      "          6       0.93      0.96      0.94        26\n",
      "          7       0.73      0.66      0.69        56\n",
      "          8       0.98      1.00      0.99        45\n",
      "          9       0.98      0.95      0.97        65\n",
      "         10       0.95      0.90      0.92        20\n",
      "         11       0.92      0.88      0.90        25\n",
      "\n",
      "avg / total       0.90      0.90      0.90       531\n",
      "\n",
      "[[ 32   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  46   0   2   0   0   0   1   0   0   0   0]\n",
      " [  0   1   6   1   0   0   1   0   0   0   1   0]\n",
      " [  0   0   0 104   0   0   0  12   0   0   0   0]\n",
      " [  0   0   0   0  53   5   1   1   0   0   0   0]\n",
      " [  0   0   0   0   0  26   0   0   0   1   0   0]\n",
      " [  0   0   0   1   0   0  25   0   0   0   0   0]\n",
      " [  0   0   0  19   0   0   0  37   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  45   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1  62   0   2]\n",
      " [  0   2   0   0   0   0   0   0   0   0  18   0]\n",
      " [  0   0   0   0   0   3   0   0   0   0   0  22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "expected = y_test\n",
    "predicted  = scores\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
